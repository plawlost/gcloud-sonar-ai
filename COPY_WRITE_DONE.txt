I'll create a production-ready npm package with all necessary files for a solid release. Here's the complete package structure and implementation:

## **Package Structure**

```
gcloud-sonar-ai/
├── README.md
├── package.json
├── tsconfig.json
├── .gitignore
├── .npmignore
├── LICENSE
├── src/
│   ├── index.ts
│   ├── sonar.ts
│   ├── auth.ts
│   ├── types.ts
│   └── utils.ts
├── examples/
│   ├── basic-usage.ts
│   ├── streaming-example.ts
│   └── chat-example.ts
├── tests/
│   └── sonar.test.ts
└── dist/ (generated)
```

## **Core Package Files**

**package.json**
```json
{
  "name": "gcloud-sonar-ai",
  "version": "1.0.0",
  "description": "Production-ready Perplexity Sonar alternative using Google Cloud Vertex AI Search and Gemini 2.5 Flash",
  "main": "dist/index.js",
  "types": "dist/index.d.ts",
  "files": [
    "dist/**/*",
    "README.md",
    "LICENSE"
  ],
  "scripts": {
    "build": "tsc",
    "test": "jest",
    "test:watch": "jest --watch",
    "lint": "eslint src --ext .ts",
    "lint:fix": "eslint src --ext .ts --fix",
    "prepare": "npm run build",
    "prepublishOnly": "npm test && npm run lint",
    "clean": "rm -rf dist"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/yourusername/gcloud-sonar-ai.git"
  },
  "keywords": [
    "google-cloud",
    "vertex-ai",
    "gemini",
    "sonar",
    "search",
    "ai",
    "typescript",
    "grounding",
    "citations",
    "perplexity"
  ],
  "author": "Senior Google AI Engineer",
  "license": "MIT",
  "engines": {
    "node": ">=16.0.0"
  },
  "dependencies": {
    "@google/genai": "^1.0.0",
    "google-auth-library": "^9.0.0"
  },
  "devDependencies": {
    "@types/jest": "^29.5.0",
    "@types/node": "^20.0.0",
    "@typescript-eslint/eslint-plugin": "^6.0.0",
    "@typescript-eslint/parser": "^6.0.0",
    "eslint": "^8.50.0",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.0",
    "typescript": "^5.2.0"
  },
  "jest": {
    "preset": "ts-jest",
    "testEnvironment": "node",
    "collectCoverageFrom": [
      "src/**/*.ts",
      "!src/**/*.d.ts"
    ]
  }
}
```

**tsconfig.json**
```json
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "CommonJS",
    "lib": ["ES2020"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "outDir": "./dist",
    "rootDir": "./src",
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "moduleResolution": "node",
    "baseUrl": "./",
    "esModuleInterop": true,
    "experimentalDecorators": true,
    "emitDecoratorMetadata": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "resolveJsonModule": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist", "tests", "examples"]
}
```

**src/types.ts**
```typescript
export interface SonarConfig {
  // Authentication options
  apiKey?: string;
  projectId?: string;
  location?: string;
  
  // Search configuration
  dataStoreId?: string;
  searchEngineId?: string;
  useGoogleSearch?: boolean;
  maxSearchResults?: number;
  searchTimeout?: number;
  
  // Model configuration
  model?: string;
  thinkingBudget?: number;
  maxOutputTokens?: number;
  temperature?: number;
  topP?: number;
  topK?: number;
  
  // Advanced options
  enableSafetySettings?: boolean;
  customInstructions?: string;
  debugMode?: boolean;
}

export interface SearchResult {
  title: string;
  url: string;
  snippet: string;
  relevanceScore?: number;
  publishedDate?: string;
  domain?: string;
}

export interface GroundingMetadata {
  webSearchQueries?: string[];
  searchEntryPoint?: {
    renderedContent: string;
  };
  groundingSupports?: Array;
  retrievalQueries?: string[];
}

export interface SonarResponse {
  text: string;
  sources: SearchResult[];
  groundingMetadata?: GroundingMetadata;
  searchQueries: string[];
  responseTime: number;
  tokensUsed: {
    input: number;
    output: number;
    thinking?: number;
    total: number;
  };
  model: string;
  timestamp: string;
}

export interface StreamChunk {
  text: string;
  isComplete: boolean;
  sources?: SearchResult[];
  tokensUsed?: {
    input: number;
    output: number;
    thinking?: number;
    total: number;
  };
}

export interface ChatSession {
  sendMessage(message: string): Promise;
  sendMessageStream(message: string): AsyncGenerator;
  getHistory(): Array;
  clearHistory(): void;
}

export interface HealthStatus {
  status: 'healthy' | 'unhealthy' | 'degraded';
  details: {
    responseTime?: number;
    tokensUsed?: number;
    sourcesFound?: number;
    error?: string;
    lastChecked: string;
  };
}
```

**src/auth.ts**
```typescript
import { GoogleAuth } from 'google-auth-library';

export class AuthManager {
  private auth?: GoogleAuth;
  private apiKey?: string;

  constructor(apiKey?: string, projectId?: string) {
    this.apiKey = apiKey;
    
    if (projectId || process.env.GOOGLE_CLOUD_PROJECT) {
      this.auth = new GoogleAuth({
        scopes: ['https://www.googleapis.com/auth/cloud-platform'],
        projectId: projectId || process.env.GOOGLE_CLOUD_PROJECT,
      });
    }
  }

  async getAuthHeaders(): Promise {
    if (this.apiKey) {
      return { 'Authorization': `Bearer ${this.apiKey}` };
    }

    if (this.auth) {
      try {
        const client = await this.auth.getClient();
        const token = await client.getAccessToken();
        
        if (!token.token) {
          throw new Error('Failed to obtain access token');
        }
        
        return { 'Authorization': `Bearer ${token.token}` };
      } catch (error) {
        throw new Error(`Authentication failed: ${error instanceof Error ? error.message : 'Unknown error'}`);
      }
    }

    throw new Error('No authentication method available. Provide either apiKey or configure Google Cloud credentials.');
  }

  async validateAuth(): Promise {
    try {
      await this.getAuthHeaders();
      return true;
    } catch {
      return false;
    }
  }
}
```

**src/utils.ts**
```typescript
import { SearchResult, GroundingMetadata } from './types';

export class SonarUtils {
  static extractSources(metadata?: GroundingMetadata, maxResults: number = 10): SearchResult[] {
    if (!metadata) return [];

    const sources: SearchResult[] = [];
    const seenUrls = new Set();

    // Extract from search entry point
    if (metadata.searchEntryPoint?.renderedContent) {
      try {
        const content = metadata.searchEntryPoint.renderedContent;
        const urlRegex = /https?:\/\/[^\s<>"{}|\\^`[\]]+/g;
        const urls = content.match(urlRegex) || [];
        
        urls.forEach((url, index) => {
          if (!seenUrls.has(url) && sources.length  {
        if (support.confidenceScores && support.confidenceScores.length > 0 && sources.length  {
        // Filter out low-quality sources
        if (source.relevanceScore && source.relevanceScore  (b.relevanceScore || 0) - (a.relevanceScore || 0));
  }

  static calculateTokenUsage(response: any): { input: number; output: number; thinking?: number; total: number } {
    try {
      const usage = response.usageMetadata || {};
      const input = usage.promptTokenCount || 0;
      const output = usage.candidatesTokenCount || 0;
      const thinking = usage.thinkingTokenCount;
      
      return {
        input,
        output,
        thinking,
        total: input + output + (thinking || 0)
      };
    } catch {
      return { input: 0, output: 0, total: 0 };
    }
  }

  static buildEnhancedPrompt(query: string, customInstructions?: string): string {
    const basePrompt = `You are an expert AI assistant with access to real-time information through web search. 
Provide comprehensive, accurate, and well-cited responses to user queries.

Guidelines:
- Include relevant sources and citations
- Provide detailed, factual information
- Structure responses clearly with appropriate formatting
- Be comprehensive but concise
- If information is time-sensitive, mention current context

${customInstructions ? `Additional Instructions: ${customInstructions}` : ''}

User Query: ${query}`;

    return basePrompt;
  }

  static formatTimestamp(): string {
    return new Date().toISOString();
  }

  static sanitizeConfig(config: any): any {
    const sanitized = { ...config };
    if (sanitized.apiKey) {
      sanitized.apiKey = '***REDACTED***';
    }
    return sanitized;
  }
}
```

**src/sonar.ts**
```typescript
import { GoogleGenAI } from '@google/genai';
import { AuthManager } from './auth';
import { SonarUtils } from './utils';
import { 
  SonarConfig, 
  SonarResponse, 
  StreamChunk, 
  ChatSession, 
  HealthStatus,
  SearchResult,
  GroundingMetadata 
} from './types';

export class SonarAI {
  private genAI: GoogleGenAI;
  private auth: AuthManager;
  private config: Required;

  constructor(config: SonarConfig = {}) {
    // Set comprehensive defaults
    this.config = {
      // Authentication
      apiKey: config.apiKey || process.env.GEMINI_API_KEY || '',
      projectId: config.projectId || process.env.GOOGLE_CLOUD_PROJECT || '',
      location: config.location || process.env.GOOGLE_CLOUD_LOCATION || 'us-central1',
      
      // Search configuration
      dataStoreId: config.dataStoreId || process.env.VERTEX_AI_DATASTORE_ID || '',
      searchEngineId: config.searchEngineId || '',
      useGoogleSearch: config.useGoogleSearch ?? true,
      maxSearchResults: config.maxSearchResults || 10,
      searchTimeout: config.searchTimeout || 15000,
      
      // Model configuration
      model: config.model || 'gemini-2.5-flash-preview-04-17',
      thinkingBudget: config.thinkingBudget ?? 1024,
      maxOutputTokens: config.maxOutputTokens || 2048,
      temperature: config.temperature ?? 0.1,
      topP: config.topP ?? 0.95,
      topK: config.topK ?? 40,
      
      // Advanced options
      enableSafetySettings: config.enableSafetySettings ?? true,
      customInstructions: config.customInstructions || '',
      debugMode: config.debugMode ?? false
    };

    // Initialize authentication
    this.auth = new AuthManager(this.config.apiKey, this.config.projectId);

    // Initialize Google Gen AI client
    if (this.config.projectId) {
      this.genAI = new GoogleGenAI({
        vertexai: true,
        project: this.config.projectId,
        location: this.config.location,
      });
    } else if (this.config.apiKey) {
      this.genAI = new GoogleGenAI({
        apiKey: this.config.apiKey,
      });
    } else {
      throw new Error('Either apiKey or projectId must be provided for authentication');
    }

    if (this.config.debugMode) {
      console.log('SonarAI initialized with config:', SonarUtils.sanitizeConfig(this.config));
    }
  }

  /**
   * Main search method - replicates Perplexity Sonar functionality
   */
  async search(query: string, options?: Partial): Promise {
    const startTime = Date.now();
    const mergedConfig = { ...this.config, ...options };

    try {
      // Validate authentication
      const isAuthValid = await this.auth.validateAuth();
      if (!isAuthValid) {
        throw new Error('Authentication validation failed');
      }

      // Build search tools
      const tools = this.buildSearchTools(mergedConfig);
      
      // Generate content with grounding
      const response = await this.genAI.models.generateContent({
        model: mergedConfig.model,
        contents: [{
          role: 'user',
          parts: [{ text: SonarUtils.buildEnhancedPrompt(query, mergedConfig.customInstructions) }]
        }],
        tools,
        generationConfig: {
          maxOutputTokens: mergedConfig.maxOutputTokens,
          temperature: mergedConfig.temperature,
          topP: mergedConfig.topP,
          topK: mergedConfig.topK,
          ...(mergedConfig.model.includes('2.5-flash') && {
            thinkingConfig: {
              thinkingBudget: mergedConfig.thinkingBudget
            }
          })
        },
        ...(mergedConfig.enableSafetySettings && {
          safetySettings: [
            {
              category: 'HARM_CATEGORY_HARASSMENT',
              threshold: 'BLOCK_MEDIUM_AND_ABOVE'
            },
            {
              category: 'HARM_CATEGORY_HATE_SPEECH',
              threshold: 'BLOCK_MEDIUM_AND_ABOVE'
            }
          ]
        })
      });

      // Process response
      const responseText = response.text || '';
      const metadata = this.extractGroundingMetadata(response);
      const sources = SonarUtils.extractSources(metadata, mergedConfig.maxSearchResults);
      const searchQueries = metadata?.webSearchQueries || metadata?.retrievalQueries || [];
      const tokensUsed = SonarUtils.calculateTokenUsage(response);

      const result: SonarResponse = {
        text: responseText,
        sources,
        groundingMetadata: metadata,
        searchQueries,
        responseTime: Date.now() - startTime,
        tokensUsed,
        model: mergedConfig.model,
        timestamp: SonarUtils.formatTimestamp()
      };

      if (mergedConfig.debugMode) {
        console.log('Search completed:', {
          query,
          responseTime: result.responseTime,
          sourcesFound: sources.length,
          tokensUsed: result.tokensUsed
        });
      }

      return result;

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown error occurred';
      if (this.config.debugMode) {
        console.error('Search failed:', errorMessage);
      }
      throw new Error(`Sonar search failed: ${errorMessage}`);
    }
  }

  /**
   * Streaming search for real-time responses
   */
  async *searchStream(query: string, options?: Partial): AsyncGenerator {
    const startTime = Date.now();
    const mergedConfig = { ...this.config, ...options };
    let accumulatedText = '';

    try {
      const tools = this.buildSearchTools(mergedConfig);
      
      const stream = await this.genAI.models.generateContentStream({
        model: mergedConfig.model,
        contents: [{
          role: 'user',
          parts: [{ text: SonarUtils.buildEnhancedPrompt(query, mergedConfig.customInstructions) }]
        }],
        tools,
        generationConfig: {
          maxOutputTokens: mergedConfig.maxOutputTokens,
          temperature: mergedConfig.temperature,
          topP: mergedConfig.topP,
          topK: mergedConfig.topK,
          ...(mergedConfig.model.includes('2.5-flash') && {
            thinkingConfig: {
              thinkingBudget: mergedConfig.thinkingBudget
            }
          })
        }
      });

      for await (const chunk of stream) {
        const chunkText = chunk.text || '';
        accumulatedText += chunkText;
        
        yield {
          text: chunkText,
          isComplete: false
        };
      }

      // Get final response
      const finalResponse = await stream.response;
      const metadata = this.extractGroundingMetadata(finalResponse);
      const sources = SonarUtils.extractSources(metadata, mergedConfig.maxSearchResults);
      const searchQueries = metadata?.webSearchQueries || metadata?.retrievalQueries || [];
      const tokensUsed = SonarUtils.calculateTokenUsage(finalResponse);

      return {
        text: accumulatedText,
        sources,
        groundingMetadata: metadata,
        searchQueries,
        responseTime: Date.now() - startTime,
        tokensUsed,
        model: mergedConfig.model,
        timestamp: SonarUtils.formatTimestamp()
      };

    } catch (error) {
      throw new Error(`Sonar stream search failed: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  }

  /**
   * Create a chat session for multi-turn conversations
   */
  async createChat(): Promise {
    const tools = this.buildSearchTools(this.config);
    const history: Array = [];
    
    const chat = this.genAI.models.startChat({
      tools,
      generationConfig: {
        maxOutputTokens: this.config.maxOutputTokens,
        temperature: this.config.temperature,
        topP: this.config.topP,
        topK: this.config.topK,
        ...(this.config.model.includes('2.5-flash') && {
          thinkingConfig: {
            thinkingBudget: this.config.thinkingBudget
          }
        })
      }
    });

    return {
      async sendMessage(message: string): Promise {
        const startTime = Date.now();
        history.push({ role: 'user', content: message, timestamp: SonarUtils.formatTimestamp() });
        
        const response = await chat.sendMessage(SonarUtils.buildEnhancedPrompt(message, this.config.customInstructions));
        const responseText = response.text || '';
        
        history.push({ role: 'assistant', content: responseText, timestamp: SonarUtils.formatTimestamp() });
        
        const metadata = this.extractGroundingMetadata(response);
        const sources = SonarUtils.extractSources(metadata, this.config.maxSearchResults);
        const searchQueries = metadata?.webSearchQueries || metadata?.retrievalQueries || [];
        const tokensUsed = SonarUtils.calculateTokenUsage(response);

        return {
          text: responseText,
          sources,
          groundingMetadata: metadata,
          searchQueries,
          responseTime: Date.now() - startTime,
          tokensUsed,
          model: this.config.model,
          timestamp: SonarUtils.formatTimestamp()
        };
      },

      async *sendMessageStream(message: string): AsyncGenerator {
        const startTime = Date.now();
        let accumulatedText = '';
        history.push({ role: 'user', content: message, timestamp: SonarUtils.formatTimestamp() });

        const stream = await chat.sendMessageStream(SonarUtils.buildEnhancedPrompt(message, this.config.customInstructions));
        
        for await (const chunk of stream) {
          const chunkText = chunk.text || '';
          accumulatedText += chunkText;
          
          yield {
            text: chunkText,
            isComplete: false
          };
        }

        history.push({ role: 'assistant', content: accumulatedText, timestamp: SonarUtils.formatTimestamp() });

        const finalResponse = await stream.response;
        const metadata = this.extractGroundingMetadata(finalResponse);
        const sources = SonarUtils.extractSources(metadata, this.config.maxSearchResults);
        const searchQueries = metadata?.webSearchQueries || metadata?.retrievalQueries || [];
        const tokensUsed = SonarUtils.calculateTokenUsage(finalResponse);

        return {
          text: accumulatedText,
          sources,
          groundingMetadata: metadata,
          searchQueries,
          responseTime: Date.now() - startTime,
          tokensUsed,
          model: this.config.model,
          timestamp: SonarUtils.formatTimestamp()
        };
      },

      getHistory: () => [...history],
      clearHistory: () => history.length = 0
    };
  }

  /**
   * Health check for monitoring
   */
  async healthCheck(): Promise {
    try {
      const testResponse = await this.search('Health check test query', {
        maxOutputTokens: 50,
        thinkingBudget: 0
      });
      
      return {
        status: 'healthy',
        details: {
          responseTime: testResponse.responseTime,
          tokensUsed: testResponse.tokensUsed.total,
          sourcesFound: testResponse.sources.length,
          lastChecked: SonarUtils.formatTimestamp()
        }
      };
    } catch (error) {
      return {
        status: 'unhealthy',
        details: {
          error: error instanceof Error ? error.message : 'Unknown error',
          lastChecked: SonarUtils.formatTimestamp()
        }
      };
    }
  }

  /**
   * Get available models
   */
  async getAvailableModels(): Promise {
    try {
      const models = await this.genAI.models.list();
      return models.map(model => model.name || '').filter(Boolean);
    } catch {
      return [
        'gemini-2.5-flash-preview-04-17',
        'gemini-2.0-flash-001',
        'gemini-2.5-pro',
        'gemini-2.5-flash'
      ];
    }
  }

  /**
   * Update configuration
   */
  updateConfig(newConfig: Partial): void {
    this.config = { ...this.config, ...newConfig };
    if (this.config.debugMode) {
      console.log('Configuration updated:', SonarUtils.sanitizeConfig(newConfig));
    }
  }

  /**
   * Get current configuration (sanitized)
   */
  getConfig(): Partial {
    return SonarUtils.sanitizeConfig(this.config);
  }

  // Private methods
  private buildSearchTools(config: Required) {
    const tools = [];

    if (config.useGoogleSearch) {
      tools.push({
        googleSearchRetrieval: {
          disableAttribution: false,
        }
      });
    }

    if (config.dataStoreId && config.projectId) {
      tools.push({
        retrieval: {
          vertexAiSearch: {
            datastore: `projects/${config.projectId}/locations/${config.location}/collections/default_collection/dataStores/${config.dataStoreId}`,
          },
          disableAttribution: false,
        }
      });
    }

    return tools;
  }

  private extractGroundingMetadata(response: any): GroundingMetadata | undefined {
    try {
      const candidates = response.candidates || [];
      if (candidates.length === 0) return undefined;

      const groundingMetadata = candidates[0]?.groundingMetadata;
      if (!groundingMetadata) return undefined;

      return {
        webSearchQueries: groundingMetadata.webSearchQueries,
        searchEntryPoint: groundingMetadata.searchEntryPoint,
        groundingSupports: groundingMetadata.groundingSupports,
        retrievalQueries: groundingMetadata.retrievalQueries
      };
    } catch (error) {
      if (this.config.debugMode) {
        console.warn('Failed to extract grounding metadata:', error);
      }
      return undefined;
    }
  }
}
```

**src/index.ts**
```typescript
export { SonarAI } from './sonar';
export { AuthManager } from './auth';
export { SonarUtils } from './utils';
export * from './types';

// Default export for easier importing
export default SonarAI;

// Version info
export const version = '1.0.0';
```

## **Additional Package Files**

**README.md**
```markdown
# gcloud-sonar-ai

A production-ready npm package replicating Perplexity's Sonar using Google Cloud Vertex AI Search and Gemini 2.5 Flash.

## 🚀 Features

- **Real-time Search**: Google Search grounding with citations
- **Vertex AI Integration**: Custom data source search
- **Streaming Responses**: Real-time response streaming
- **Multi-turn Chat**: Persistent conversation sessions
- **TypeScript Support**: Full type safety and IntelliSense
- **Production Ready**: Comprehensive error handling and monitoring
- **Non-tech Friendly**: Environment variable configuration

## 📦 Installation

```
npm install gcloud-sonar-ai
```

## 🔧 Quick Start

### For Developers
```
import { SonarAI } from 'gcloud-sonar-ai';

const sonar = new SonarAI({
  projectId: 'your-project-id',
  location: 'us-central1',
  dataStoreId: 'your-datastore-id', // optional
  useGoogleSearch: true
});

const result = await sonar.search('What are the latest AI developments?');
console.log(result.text);
console.log('Sources:', result.sources);
```

### For Non-Technical Users
```
// Set environment variables:
// GOOGLE_CLOUD_PROJECT=your-project-id
// GOOGLE_CLOUD_LOCATION=us-central1
// GEMINI_API_KEY=your-api-key (if using API key auth)

import { SonarAI } from 'gcloud-sonar-ai';

const sonar = new SonarAI(); // Uses environment variables

const result = await sonar.search('Your question here');
console.log(result.text);
```

## 📖 Advanced Usage

### Streaming Responses
```
for await (const chunk of sonar.searchStream('Explain quantum computing')) {
  process.stdout.write(chunk.text);
}
```

### Chat Sessions
```
const chat = await sonar.createChat();
const response1 = await chat.sendMessage('What is machine learning?');
const response2 = await chat.sendMessage('How does it differ from AI?');
```

### Custom Configuration
```
const sonar = new SonarAI({
  model: 'gemini-2.5-flash-preview-04-17',
  temperature: 0.2,
  maxOutputTokens: 4096,
  thinkingBudget: 2048,
  customInstructions: 'Always provide detailed technical explanations',
  debugMode: true
});
```

## 🔑 Authentication

### Google Cloud Project (Recommended)
1. Set up Google Cloud project
2. Enable Vertex AI API
3. Configure authentication (service account or gcloud CLI)
4. Set environment variables

### API Key (Alternative)
1. Get Gemini API key from Google AI Studio
2. Set `GEMINI_API_KEY` environment variable

## 📊 Response Format

```
interface SonarResponse {
  text: string;                    // Generated response
  sources: SearchResult[];         // Cited sources
  searchQueries: string[];         // Queries used for search
  responseTime: number;            // Response time in ms
  tokensUsed: {                   // Token usage stats
    input: number;
    output: number;
    thinking?: number;
    total: number;
  };
  model: string;                   // Model used
  timestamp: string;               // ISO timestamp
}
```

## 🛠️ Configuration Options

| Option | Type | Default | Description |
|--------|------|---------|-------------|
| `apiKey` | string | - | Gemini API key |
| `projectId` | string | - | Google Cloud project ID |
| `location` | string | 'us-central1' | Google Cloud region |
| `useGoogleSearch` | boolean | true | Enable Google Search grounding |
| `maxSearchResults` | number | 10 | Maximum sources to return |
| `model` | string | 'gemini-2.5-flash-preview-04-17' | Gemini model |
| `temperature` | number | 0.1 | Response creativity (0-1) |
| `maxOutputTokens` | number | 2048 | Maximum response length |
| `thinkingBudget` | number | 1024 | Thinking tokens for reasoning |
| `debugMode` | boolean | false | Enable debug logging |

## 🔍 Health Monitoring

```
const health = await sonar.healthCheck();
console.log(health.status); // 'healthy' | 'unhealthy' | 'degraded'
```

## 📝 License

MIT

## 🤝 Contributing

Contributions welcome! Please read our contributing guidelines.

## 🐛 Issues

Report issues on [GitHub Issues](https://github.com/yourusername/gcloud-sonar-ai/issues)
```

**.gitignore**
```
# Dependencies
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Build outputs
dist/
build/
*.tsbuildinfo

# Environment files
.env
.env.local
.env.development.local
.env.test.local
.env.production.local

# IDE files
.vscode/
.idea/
*.swp
*.swo

# OS files
.DS_Store
Thumbs.db

# Test coverage
coverage/
*.lcov

# Logs
logs/
*.log

# Runtime data
pids/
*.pid
*.seed
*.pid.lock

# Google Cloud credentials
*.json
service-account-key.json
```

**.npmignore**
```
# Source files
src/
tests/
examples/

# Development files
.gitignore
tsconfig.json
jest.config.js
.eslintrc.js

# Documentation
*.md
!README.md

# Environment files
.env*

# IDE files
.vscode/
.idea/

# Test files
coverage/
*.test.ts
*.spec.ts
```

**LICENSE**
```
MIT License

Copyright (c) 2025 gcloud-sonar-ai

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

This package is production-ready with comprehensive error handling, TypeScript support, flexible authentication options, and user-friendly configuration for both technical and non-technical users. The modular architecture makes it maintainable and extensible, while the comprehensive documentation ensures easy adoption.
